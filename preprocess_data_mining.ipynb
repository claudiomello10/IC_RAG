{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required modules\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# creating a pdf reader object\n",
    "reader = PdfReader('7_data_mining_-_practical_machine_learning_tools_and_techniques_3rd_ed_.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665\n",
      "This page intentionally left blank\n"
     ]
    }
   ],
   "source": [
    "# printing number of pages in pdf file\n",
    "print(len(reader.pages))\n",
    "\n",
    "# getting a specific page from the pdf file\n",
    "page = reader.pages[2]\n",
    "\n",
    "# extracting text from page\n",
    "text = page.extract_text()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Title</th>\n",
       "      <th>Page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What’s It All About?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Input: Concepts, Instances, and Attributes</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Output: Knowledge Representation</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Algorithms: The Basic Methods</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Credibility: Evaluating What’s Been Learned</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Implementations: Real Machine Learning Schemes</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Data Transformations</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Moving on: Applications and Beyond</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Introduction to Weka</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>The Explorer</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>The Knowledge Flow Interface</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>The Experimenter</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>The Command-Line Interface</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Embedded Machine Learning</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Writing New Learning Schemes</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Tutorial Exercises for the Weka Explorer</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Chapter                                           Title Page\n",
       "0        1                            What’s It All About?    3\n",
       "1        2      Input: Concepts, Instances, and Attributes   39\n",
       "2        3                Output: Knowledge Representation   61\n",
       "3        4                   Algorithms: The Basic Methods   85\n",
       "4        5     Credibility: Evaluating What’s Been Learned  147\n",
       "5        6  Implementations: Real Machine Learning Schemes  191\n",
       "6        7                            Data Transformations  305\n",
       "7        8                               Ensemble Learning  351\n",
       "8        9              Moving on: Applications and Beyond  375\n",
       "9       10                            Introduction to Weka  403\n",
       "10      11                                    The Explorer  407\n",
       "11      12                    The Knowledge Flow Interface  495\n",
       "12      13                                The Experimenter  505\n",
       "13      14                      The Command-Line Interface  519\n",
       "14      15                       Embedded Machine Learning  531\n",
       "15      16                    Writing New Learning Schemes  539\n",
       "16      17        Tutorial Exercises for the Weka Explorer  559"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the chapter titles\n",
    "\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "summary_df = pd.DataFrame(columns=['Chapter', 'Title', 'Page'])\n",
    "\n",
    "for i in range(5, 15):\n",
    "    page_text = reader.pages[i].extract_text()\n",
    "    page_text = page_text.split('xxxiii')[-1]\n",
    "    #print(page_text)\n",
    "    page_text = page_text.split('\\n')\n",
    "    # Get the ones that start with a number than a dot\n",
    "    for line in page_text:\n",
    "        if re.match(r'CHAPTER \\d+', line, re.IGNORECASE):\n",
    "            chapter = re.findall(r'CHAPTER \\d+', line, re.IGNORECASE)[0]\n",
    "            chapter = int(chapter.split(' ')[-1])\n",
    "            title = re.sub(r'^\\d+\\.', '', line)\n",
    "            # Get the page at the end of the chapter name\n",
    "            page = re.findall(r'\\d+$', title)[-1]\n",
    "            page = int(page)\n",
    "\n",
    "            # Remove the dots from the title\n",
    "            title = re.sub(r'\\.', '', title)\n",
    "\n",
    "            # Remove the page number from the title\n",
    "            title = re.sub(r'\\d+$', '', title)\n",
    "\n",
    "            # Remove the CHAPTER number from the title\n",
    "            title = re.sub(r'CHAPTER \\d+', '', title, flags=re.IGNORECASE)\n",
    "\n",
    "            \n",
    "\n",
    "            # Remove the spaces at the end of the title\n",
    "            title = title.strip()\n",
    "\n",
    "            \n",
    "\n",
    "            summary_df = summary_df._append({'Chapter': chapter, 'Title': title, 'Page': page}, ignore_index=True)\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title 1: What’s It All About?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1149, which is longer than the specified 1000\n",
      "Created a chunk of size 1030, which is longer than the specified 1000\n",
      "Created a chunk of size 1417, which is longer than the specified 1000\n",
      "Created a chunk of size 1217, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title 2: Input: Concepts, Instances, and Attributes\n",
      "Title 3: Output: Knowledge Representation\n",
      "Title 4: Algorithms: The Basic Methods\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1206, which is longer than the specified 1000\n",
      "Created a chunk of size 1251, which is longer than the specified 1000\n",
      "Created a chunk of size 2255, which is longer than the specified 1000\n",
      "Created a chunk of size 2763, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title 5: Credibility: Evaluating What’s Been Learned\n",
      "Title 6: Implementations: Real Machine Learning Schemes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2429, which is longer than the specified 1000\n",
      "Created a chunk of size 1095, which is longer than the specified 1000\n",
      "Created a chunk of size 1997, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title 7: Data Transformations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2549, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title 8: Ensemble Learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1421, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title 9: Moving on: Applications and Beyond\n",
      "Title 10: Introduction to Weka\n",
      "Title 11: The Explorer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1517, which is longer than the specified 1000\n",
      "Created a chunk of size 1863, which is longer than the specified 1000\n",
      "Created a chunk of size 3445, which is longer than the specified 1000\n",
      "Created a chunk of size 1515, which is longer than the specified 1000\n",
      "Created a chunk of size 1389, which is longer than the specified 1000\n",
      "Created a chunk of size 5082, which is longer than the specified 1000\n",
      "Created a chunk of size 1104, which is longer than the specified 1000\n",
      "Created a chunk of size 1697, which is longer than the specified 1000\n",
      "Created a chunk of size 1126, which is longer than the specified 1000\n",
      "Created a chunk of size 1103, which is longer than the specified 1000\n",
      "Created a chunk of size 2395, which is longer than the specified 1000\n",
      "Created a chunk of size 3166, which is longer than the specified 1000\n",
      "Created a chunk of size 2136, which is longer than the specified 1000\n",
      "Created a chunk of size 2533, which is longer than the specified 1000\n",
      "Created a chunk of size 1032, which is longer than the specified 1000\n",
      "Created a chunk of size 1094, which is longer than the specified 1000\n",
      "Created a chunk of size 2612, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title 12: The Knowledge Flow Interface\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1375, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title 13: The Experimenter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2094, which is longer than the specified 1000\n",
      "Created a chunk of size 1376, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title 14: The Command-Line Interface\n",
      "Title 15: Embedded Machine Learning\n",
      "Title 16: Writing New Learning Schemes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1010, which is longer than the specified 1000\n",
      "Created a chunk of size 1157, which is longer than the specified 1000\n",
      "Created a chunk of size 1222, which is longer than the specified 1000\n",
      "Created a chunk of size 1416, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title 17: Tutorial Exercises for the Weka Explorer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1298, which is longer than the specified 1000\n",
      "Created a chunk of size 1963, which is longer than the specified 1000\n",
      "Created a chunk of size 1176, which is longer than the specified 1000\n",
      "Created a chunk of size 1033, which is longer than the specified 1000\n",
      "Created a chunk of size 1351, which is longer than the specified 1000\n",
      "Created a chunk of size 2125, which is longer than the specified 1000\n",
      "Created a chunk of size 1659, which is longer than the specified 1000\n",
      "Created a chunk of size 4100, which is longer than the specified 1000\n",
      "Created a chunk of size 4771, which is longer than the specified 1000\n",
      "Created a chunk of size 4861, which is longer than the specified 1000\n",
      "Created a chunk of size 1664, which is longer than the specified 1000\n",
      "Created a chunk of size 1366, which is longer than the specified 1000\n",
      "Created a chunk of size 3880, which is longer than the specified 1000\n",
      "Created a chunk of size 1562, which is longer than the specified 1000\n",
      "Created a chunk of size 1237, which is longer than the specified 1000\n",
      "Created a chunk of size 2837, which is longer than the specified 1000\n",
      "Created a chunk of size 3550, which is longer than the specified 1000\n",
      "Created a chunk of size 1197, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "# Get the text from all the chapters and save it to a df\n",
    "\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "text_splitter = NLTKTextSplitter(chunk_size=1000, separator='\\n')\n",
    "full_df = pd.DataFrame(columns=['Chapter', 'Title', 'Text'])\n",
    "\n",
    "page_correction = 36\n",
    "\n",
    "for i in range(0, len(summary_df)):\n",
    "    initial_page = summary_df.iloc[i]['Page'] + page_correction\n",
    "    if i == len(summary_df) - 1:\n",
    "        final_page = len(reader.pages)\n",
    "    else:    \n",
    "        final_page = summary_df.iloc[i + 1]['Page'] + page_correction\n",
    "\n",
    "    chapter_text = ''\n",
    "\n",
    "    print(f\"Title {i+1}: {summary_df.iloc[i]['Title']}\")\n",
    "\n",
    "    for j in range(initial_page, final_page):\n",
    "        page_text = reader.pages[j].extract_text()\n",
    "\n",
    "        page_text = page_text.split('\\n')\n",
    "\n",
    "        # Get the ones with \"26 | Chapter 1:\"\n",
    "        for line in page_text:\n",
    "            chapter_text += line\n",
    "\n",
    "    # Divide the text into chunks\n",
    "    chapter_chunks = text_splitter.split_text(chapter_text)\n",
    "\n",
    "    #print(f\"Number of chunks: {len(chapter_chunks)}\")\n",
    "\n",
    "    for chunk in chapter_chunks:\n",
    "        full_df = full_df._append({'Chapter': summary_df.iloc[i]['Chapter'], 'Title': summary_df.iloc[i]['Title'], 'Text': chunk}, ignore_index=True)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "full_df.to_csv('data_mining.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1900"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.__len__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
